/home/jamilg/anaconda3/envs/AO/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
/home/jamilg/anaconda3/envs/AO/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
/home/jamilg/anaconda3/envs/AO/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
/home/jamilg/anaconda3/envs/AO/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
Training UMAP:   0%|          | 0/157 [00:00<?, ?it/s]Training UMAP:  11%|█▏        | 18/157 [00:00<00:00, 174.80it/s]Training UMAP:  23%|██▎       | 36/157 [00:00<00:01, 110.89it/s]Training UMAP:  34%|███▍      | 54/157 [00:00<00:00, 134.44it/s]Training UMAP:  46%|████▌     | 72/157 [00:00<00:00, 149.14it/s]Training UMAP:  57%|█████▋    | 90/157 [00:00<00:00, 157.79it/s]Training UMAP:  69%|██████▉   | 108/157 [00:00<00:00, 164.45it/s]Training UMAP:  80%|████████  | 126/157 [00:00<00:00, 168.18it/s]Training UMAP:  92%|█████████▏| 144/157 [00:00<00:00, 170.67it/s]Training UMAP: 100%|██████████| 157/157 [00:00<00:00, 159.19it/s]
/home/jamilg/anaconda3/envs/AO/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
/home/jamilg/anaconda3/envs/AO/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
/home/jamilg/anaconda3/envs/AO/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
/home/jamilg/anaconda3/envs/AO/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
Training UMAP:   0%|          | 0/157 [00:00<?, ?it/s]Training UMAP:  11%|█▏        | 18/157 [00:00<00:00, 178.99it/s]Training UMAP:  23%|██▎       | 36/157 [00:00<00:01, 111.30it/s]Training UMAP:  34%|███▍      | 54/157 [00:00<00:00, 134.31it/s]Training UMAP:  46%|████▌     | 72/157 [00:00<00:00, 149.02it/s]Training UMAP:  57%|█████▋    | 90/157 [00:00<00:00, 157.69it/s]Training UMAP:  69%|██████▉   | 108/157 [00:00<00:00, 163.74it/s]Training UMAP:  80%|████████  | 126/157 [00:00<00:00, 167.45it/s]Training UMAP:  92%|█████████▏| 144/157 [00:00<00:00, 169.57it/s]Training UMAP: 100%|██████████| 157/157 [00:00<00:00, 158.89it/s]
Storing reduced data:   0%|          | 0/10000 [00:00<?, ?it/s]Storing reduced data: 100%|██████████| 10000/10000 [00:00<00:00, 995585.94it/s]
/home/jamilg/Desktop/Repos/Work/Professional_Work/Code/Adversarial_Research/Adversarial_Observation/Attacks.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  input_batch_data = torch.tensor(input_batch_data).to(device)
Running Swarm:   0%|          | 0/20 [00:00<?, ?it/s]/home/jamilg/Desktop/Repos/Work/Professional_Work/Code/Adversarial_Research/Adversarial_Observation/Attacks.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  input_batch_data = torch.tensor(input_batch_data).to(device)
Running Swarm:   5%|▌         | 1/20 [13:52<4:23:29, 832.06s/it]/home/jamilg/Desktop/Repos/Work/Professional_Work/Code/Adversarial_Research/Adversarial_Observation/Attacks.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  input_batch_data = torch.tensor(input_batch_data).to(device)
Running Swarm:  10%|█         | 2/20 [27:44<4:09:40, 832.24s/it]/home/jamilg/Desktop/Repos/Work/Professional_Work/Code/Adversarial_Research/Adversarial_Observation/Attacks.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  input_batch_data = torch.tensor(input_batch_data).to(device)
Running Swarm:  15%|█▌        | 3/20 [41:34<3:55:31, 831.27s/it]/home/jamilg/Desktop/Repos/Work/Professional_Work/Code/Adversarial_Research/Adversarial_Observation/Attacks.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  input_batch_data = torch.tensor(input_batch_data).to(device)
Running Swarm:  20%|██        | 4/20 [55:31<3:42:14, 833.38s/it]/home/jamilg/Desktop/Repos/Work/Professional_Work/Code/Adversarial_Research/Adversarial_Observation/Attacks.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  input_batch_data = torch.tensor(input_batch_data).to(device)
